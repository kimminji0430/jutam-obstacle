<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>YOLO + COCO 객체 인식 음성 안내</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body { background: #181818; color: #fff; text-align: center; font-family: sans-serif; }
    #canvas { background: #111; border-radius: 16px; margin-top: 20px; }
    button { margin-top: 18px; font-size: 1.2em; padding: 0.4em 1.2em; }
  </style>
</head>
<body>
  <h2>실시간 객체 인식 + 음성 안내 (YOLO + COCO)</h2>
  <canvas id="canvas" width="640" height="640"></canvas>
  <button onclick="start()">카메라 시작</button>

  <script>
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    let video, stream, yoloSession, cocoModel;
    let lastSpoken = {};

    // YOLO 사용자 정의 클래스
    const yoloLabels = ["bar obstacle", "food waste container", "kickboard", "trash bag"];

    // COCO에서 감지할 클래스
    const cocoTargets = ["person", "bicycle"];
    const LABELS_KO = {
      "bar obstacle": "막대 장애물",
      "food waste container": "음식물 쓰레기통",
      "kickboard": "킥보드",
      "trash bag": "쓰레기봉투",
      "person": "사람",
      "bicycle": "자전거"
    };

    async function loadModels() {
      // ✅ GitHub에서 best.onnx 불러오기
      yoloSession = await ort.InferenceSession.create(
        "https://github.com/kimminji0430/jutam-obstacle/raw/main/best.onnx"
      );
      cocoModel = await cocoSsd.load();
    }

    async function start() {
      await loadModels();
      stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 640, facingMode: "environment" },
        audio: false
      });
      video = document.createElement('video');
      video.setAttribute('playsinline', true);
      video.srcObject = stream;
      await video.play();
      video.width = 640;
      video.height = 640;
      detectFrame();
    }

    function speakAlert(label) {
      const now = Date.now();
      if (!lastSpoken[label] || now - lastSpoken[label] > 3500) {
        const spoken = LABELS_KO[label] || label;
        const msg = new SpeechSynthesisUtterance(`앞에 ${attachParticle(spoken)} 있습니다. 주의하세요.`);
        msg.lang = 'ko-KR';
        window.speechSynthesis.speak(msg);
        lastSpoken[label] = now;
      }
    }

    function attachParticle(word, particle1 = '이', particle2 = '가') {
      const lastChar = word[word.length - 1];
      const uni = lastChar.charCodeAt(0);
      const hasFinal = (uni - 0xac00) % 28 !== 0;
      return word + (hasFinal ? particle1 : particle2);
    }

    async function detectFrame() {
      ctx.drawImage(video, 0, 0, 640, 640);

      // 🎯 YOLO 감지
      const imgData = ctx.getImageData(0, 0, 640, 640).data;
      const input = new Float32Array(1 * 3 * 640 * 640);
      for (let i = 0, j = 0; i < imgData.length; i += 4, j += 3) {
        input[j] = imgData[i] / 255;
        input[j+1] = imgData[i+1] / 255;
        input[j+2] = imgData[i+2] / 255;
      }
      const tensor = new ort.Tensor('float32', input, [1, 3, 640, 640]);
      const feeds = { [yoloSession.inputNames[0]]: tensor };
      const yoloResults = await yoloSession.run(feeds);
      const output = yoloResults['output0'].data;

      const numDetections = 25200;
      const numAttrs = 7;
      for (let i = 0; i < numDetections; i++) {
        const offset = i * numAttrs;
        const x = output[offset];
        const y = output[offset + 1];
        const w = output[offset + 2];
        const h = output[offset + 3];
        const conf = output[offset + 4];
        const score = output[offset + 5];
        const classId = output[offset + 6];

        if (conf * score > 0.45 && classId < yoloLabels.length) {
          const cx = x * 640;
          const cy = y * 640;
          const boxW = w * 640;
          const boxH = h * 640;
          const x0 = cx - boxW / 2;
          const y0 = cy - boxH / 2;

          const label = yoloLabels[classId];
          ctx.strokeStyle = "#38e";
          ctx.lineWidth = 2;
          ctx.strokeRect(x0, y0, boxW, boxH);
          ctx.fillStyle = "#38e";
          ctx.font = "16px sans-serif";
          ctx.fillText(label, x0, y0 > 18 ? y0 - 4 : y0 + 18);

          speakAlert(label);
        }
      }

      // 🎯 COCO 감지
      const cocoPredictions = await cocoModel.detect(video);
      cocoPredictions.forEach(pred => {
        if (cocoTargets.includes(pred.class) && pred.score > 0.6) {
          ctx.strokeStyle = "#22c55e";
          ctx.lineWidth = 2;
          ctx.strokeRect(...pred.bbox);
          ctx.font = "16px sans-serif";
          ctx.fillStyle = "#22c55e";
          ctx.fillText(pred.class, pred.bbox[0], pred.bbox[1] > 18 ? pred.bbox[1] - 4 : pred.bbox[1] + 18);
          speakAlert(pred.class);
        }
      });

      requestAnimationFrame(detectFrame);
    }
  </script>
</body>
</html>
